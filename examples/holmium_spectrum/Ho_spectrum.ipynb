{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28cb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import logging\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cmdstanpy\n",
    "from cmdstanpy import CmdStanModel\n",
    "\n",
    "from baynes.plotter import FitPlotter\n",
    "from baynes.toyMC import SpectraSampler\n",
    "from baynes.analysis import standard_analysis, multithreaded_run\n",
    "from baynes.probability import HoSpectrum, hdi\n",
    "from baynes.model_utils import *\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 13})\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "cmdstanpy.utils.get_logger().setLevel(logging.ERROR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af30a888",
   "metadata": {},
   "source": [
    "## Example 3: fit of a simulated $^{163}Ho$ spectrum endpoint and sensibility estimate\n",
    "\n",
    "### Generate MC data using SpectraSampler\n",
    "$$spectrum = ((1-bkg)A_{Ho}Ho(m_\\nu, Q)+bkg)\\otimes Normal(0, FWHM)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbf69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "A_Ho = 1\n",
    "bkg = 1e-4\n",
    "FWHM=5\n",
    "n_days = 100\n",
    "\n",
    "s = SpectraSampler({'$^{163}Ho$': [HoSpectrum, [m], A_Ho]}, flat_bkg=bkg, FWHM=FWHM, dE=1, integrate=False)\n",
    "s.plot_spectrum()\n",
    "s.set_measure_time(n_days, n_det=64)\n",
    "\n",
    "events = s.sample()[0]\n",
    "s.plot_events(events)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cb87e58",
   "metadata": {},
   "source": [
    "### Retrieve and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba81b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_file= get_stan_file(\"Ho_endpoint_simple.stan\")\n",
    "model = CmdStanModel(stan_file=stan_file,\n",
    "                     **get_compiler_kwargs())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f26ebfa8",
   "metadata": {},
   "source": [
    "### Fit the model. The steps detailed in the previous examples are run automatically using standard_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ebd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'N_bins': len(events), \n",
    "      'N_window': 51,\n",
    "      'x': s.ROI_bin_edges, \n",
    "      'counts': events,\n",
    "      'N_ev': s.n_events,\n",
    "      'p_Q': 2838,\n",
    "      'p_FWHM': FWHM,\n",
    "}\n",
    "\n",
    "sampler_kwargs={\n",
    "    'chains': 4,\n",
    "    'iter_warmup': 500,\n",
    "    'iter_sampling': 500,\n",
    "    'save_warmup': True, \n",
    "    'adapt_delta': 0.9,\n",
    "    'threads_per_chain':8\n",
    "}\n",
    "\n",
    "plot_pars = ['m_nu', 'Q', 'bkg', 'sigma']\n",
    "p = FitPlotter(col_wrap=4, style='seaborn-v0_8-whitegrid', save=True)\n",
    "fit = standard_analysis(model, data, p, sampler_kwargs, fit_title='m=0', plot_params = plot_pars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1cfde43",
   "metadata": {},
   "source": [
    "### To obtain a robust estimate of the sensibility to $m_\\nu$ the fit is repeated many times. This can be done in parallel using multithreaded_run. Result are saved in a .pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c34074",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def nu_mass_fit(m):\n",
    "    s = SpectraSampler({'$^{163}Ho$': [HoSpectrum, [m], A_Ho]}, flat_bkg=bkg, FWHM=FWHM, dE=1, integrate=False)\n",
    "    s.set_measure_time(n_days, n_det=64)\n",
    "    events = s.sample()[0]\n",
    "\n",
    "    data={'N_bins': len(events), \n",
    "          'N_window': 51,\n",
    "          'x': s.ROI_bin_edges, \n",
    "          'counts': events,\n",
    "          'N_ev': s.n_events,\n",
    "          'p_Q': 2838,un the model \n",
    "          'p_FWHM': 5,\n",
    "          'prior': 0,\n",
    "    }\n",
    "    \n",
    "    div = True\n",
    "    while div is True:\n",
    "        inits={}\n",
    "        inits['m_nu_red'] = np.random.beta(1,1.05)/3 #the initial value for m_nu shouldn't be too large\n",
    "        inits['Q'] = np.random.normal(2838, 10)\n",
    "        inits['bkg'] = np.random.beta(2.5, 20)\n",
    "        inits['sigma'] = np.random.normal(s.sigma, 0.3)\n",
    "            \n",
    "        fit = model.sample(data,\n",
    "                           chains=2,\n",
    "                           iter_warmup=500,\n",
    "                           iter_sampling=1000,\n",
    "                           save_warmup=False,\n",
    "                           show_progress=False,\n",
    "                           inits=inits,\n",
    "                           adapt_delta=0.9)\n",
    "        div = any(fit.divergences)\n",
    "    return fit\n",
    "\n",
    "n_fits = 100\n",
    "n_processes = 16\n",
    "result = multithreaded_run(nu_mass_fit, [m]*n_fits, n_processes, filename='data/'+str(m)+'_fits.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6fba1fe",
   "metadata": {},
   "source": [
    "### Open the data file and recover the posteriors for $m_\\nu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef854497",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('data/0_fits.pkl', 'rb')\n",
    "data = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "posteriors = []\n",
    "for fit in data:\n",
    "    posteriors.append(fit.draws_pd(['m_nu']).to_numpy().flatten())\n",
    "posteriors = np.array(posteriors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fdaef80",
   "metadata": {},
   "source": [
    "### Plot the posteriors and combine their samples in a histogram. The upper limit on the parameter's estimate is given by the confidence interval of this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = p.new_figure('multi').subplots()\n",
    "sns.boxplot(posteriors.transpose(), whis=[2.5, 95], showfliers=False, palette='flare', ax=ax)\n",
    "ax.figure.set_size_inches(25, 5)\n",
    "ax.set_xticks([])\n",
    "ax.set_ylabel('m_nu', fontsize=25)\n",
    "\n",
    "\n",
    "full = posteriors.flatten()\n",
    "ax = p.new_figure('multi').subplots()\n",
    "x_max=70\n",
    "\n",
    "prob = 0.68\n",
    "print( str(prob*100) + '% highest density interval: ', hdi(full, prob=0.68)) \n",
    "ax.axvspan(hdi(full, prob=prob)[1], x_max, color='gray', alpha=0.2, lw=0)\n",
    "\n",
    "prob = 0.95\n",
    "print( str(prob*100) + '% highest density interval: ', hdi(full, prob=0.68)) \n",
    "ax.axvspan(hdi(full, prob=prob)[1], x_max, color='gray', alpha=0.2, lw=0)\n",
    "\n",
    "sns.histplot(posteriors.transpose(), bins=100, alpha=1, multiple='stack', legend=False, lw=0., palette='flare', ax=ax)\n",
    "ax.grid(False)\n",
    "ax.set_xlim(0, x_max)\n",
    "ax.set_xlabel('m_nu', fontsize=14)\n",
    "ax.set_ylabel('counts', fontsize=14)\n",
    "ax.figure.set_size_inches(8, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baynesenv",
   "language": "python",
   "name": "baynesenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
